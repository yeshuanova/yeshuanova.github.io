<!DOCTYPE html>
<html class="no-js" lang="zh-tw">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>使用 TensorFlow Lite 在 iOS 裝置上進行圖片分類 - Xeno Universe</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="Image classification in iOS device using TensorFlow Lite">
	<meta name="generator" content="Hugo 0.54.0" />
	<meta property="og:title" content="使用 TensorFlow Lite 在 iOS 裝置上進行圖片分類" />
<meta property="og:description" content="Image classification in iOS device using TensorFlow Lite" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/2018/tensorflow-lite-in-ios-device/" />
<meta property="article:published_time" content="2018-01-15T12:00:00&#43;08:00"/>
<meta property="article:modified_time" content="2018-01-15T12:00:00&#43;08:00"/>

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="shortcut icon" href="/favicon.ico">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-104710641-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="Xeno Universe" rel="home">
				<div class="logo__title">Xeno Universe</div>
				<div class="logo__tagline">A fearless adventure in knowing what to do when no one’s there telling you what to do</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/about/">About</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/competitions/">Competitions</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用 TensorFlow Lite 在 iOS 裝置上進行圖片分類</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2018-01-15T12:00:00">January 15, 2018</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/categories/mobile-device" rel="category">Mobile Device</a></span>
</div>
</div>
		</header><div class="content post__content clearfix">
			<p>近幾年來由 Google 推出的 TensorFlow 在深度學習等領域有著大量的發展，但也因為由 TensorFlow 所訓練出的 Model 容量大且本身執行時也會佔用較多資源，並不適合在行動裝置上執行。因此 Google 推出了 TensorFlow Lite 讓在行動裝置上執行 TensorFlow  更為方便。本文章將簡單介紹如何在 iOS 裝置上執行 TensorFlow Lite 並進行圖像分類的方法。</p>

<h2 id="tensorflow-lite">TensorFlow Lite</h2>

<p><a href="https://www.tensorflow.org/mobile/tflite/">TensorFlow Lite</a> 是 Google 基於原先 TensorFlow Library，為行動與嵌入式裝置所推出的輕量化版本，有著較低的功耗以及記憶體空間消耗。在執行時 TensorFlow Lite 並不直接使用 TensorFlow 訓練好的模型，而是會先轉換為使用 <a href="https://google.github.io/flatbuffers/">FlatBuffers</a> 建立的新格式以減少 Model 的大小（通常命名 *<strong>.tflite</strong>）。</p>

<h2 id="在-xcode-專案中使用-tensroflow-lite">在 Xcode 專案中使用 TensroFlow Lite</h2>

<h3 id="使用-cocoapods-安裝">使用 CocoaPods 安裝</h3>

<p>要在 iOS 中使用 TensorFlow Lite，最簡單的方法就是使用 <a href="https://cocoapods.org/">CocoaPods</a> 來引入相關函式庫與連結檔。方法為安裝 CocoaPods 套件後（可使用 <a href="https://brew.sh/">Homebrew</a> 安裝），在 Project 資料夾下執行</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">pod init <span style="color:#080;background-color:#0f140f;font-style:italic"># 初始化 CocoaPods 並建立 Podfile</span></code></pre></div>
<p>執行完成後會自動建立 <strong>Podfile</strong> 檔案，接著編輯該檔案並在其中加入</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">pod <span style="color:#0086d2">&#39;TensorFlowLite&#39;</span>  <span style="color:#080;background-color:#0f140f;font-style:italic"># 安裝 TensorFlowLite library</span></code></pre></div>
<p>完成後回到 command line 介面後執行</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">pod install <span style="color:#080;background-color:#0f140f;font-style:italic"># 安裝 Library</span></code></pre></div>
<p>安裝成功後會自動建立 *<strong>.xcworkspace</strong> 檔案並引入 TensorFlow Lite 相關函式庫。</p>

<h3 id="從原始碼編譯-tensorflow-lite">從原始碼編譯 TensorFlow Lite</h3>

<p>除了使用 CocoaPods，也可以從原始碼重新編譯 TensorFlow Lite。要在 Mac OS X 上編譯 TensorFlow Lite 需先安裝  Xcode command line tools，此外也需使用到 <a href="https://en.wikipedia.org/wiki/Automake">automake</a> 與 <a href="https://en.wikipedia.org/wiki/GNU_Libtool">libtool</a> 這兩個套件（一樣可透過 <a href="http://brew.sh/">Homebrew</a> 來安裝）。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#080;background-color:#0f140f;font-style:italic"># Install Xcode command line tools (for i)</span>
xcode-select --install

<span style="color:#080;background-color:#0f140f;font-style:italic"># Install automake and libtool</span> 
brew install automake
brew install libtool</code></pre></div>
<h4 id="取得-tensorflow-原始碼">取得 TensorFlow 原始碼</h4>

<p>使用 <a href="https://git-scm.com/">Git</a> 從 <a href="https://github.com/tensorflow/tensorflow">Github</a> 上取得 Source code 或直接下載</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">git clone https://github.com/tensorflow/tensorflow.git</code></pre></div>
<p>安裝完成後切換到 TensorFlow 的資料夾中</p>

<h4 id="編譯-tensorflow-lite">編譯 TensorFlow Lite</h4>

<p>在 TensorFlow 的 root folder 位置執行以下指令</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#080;background-color:#0f140f;font-style:italic"># 下載取得相依元件</span>
tensorflow/contrib/lite/download_dependencies.sh

<span style="color:#080;background-color:#0f140f;font-style:italic"># 編譯 TensorFlow Lite</span>
tensorflow/contrib/lite/build_ios_universal_lib.sh</code></pre></div>
<p>若編譯成功則可在 <code>tensorflow/contrib/lite/gen/lib/libtensorflow-lite.a</code> 找到連結檔的位置。</p>

<blockquote>
<p>如在執行 <code>build_ios_universal_lib.sh</code> 時出現 <code>no such file or directory: 'x86_64'</code> 的錯誤，須在 Xcode &gt; Preferences &gt; Locations 中開啟 <code>Command Line Tools</code> 的選項。此外因 Tensorflow 的 master branch 是開發中的分支，可能在編譯時會出現錯誤。可先將版本切到其他版本來進行編譯試試看。</p>
</blockquote>

<h4 id="設定連結">設定連結</h4>

<p>編譯完成後，須先在 Xcode 的 Project 中設定連結在能專案中正確使用 TensorFlow API</p>

<h4 id="project-設定">Project 設定</h4>

<ul>
<li>在 <strong>Header Search Paths</strong> 中加入以下 folder 位置的路徑。

<ul>
<li>TensorFlow Code 的 root folder 位置</li>
<li><code>tensorflow/contrib/lite/downloads</code></li>
<li><code>tensorflow/contrib/lite/downloads/flatbuffers/include</code></li>
</ul></li>
<li>在 <strong>Library Search Paths</strong> 加入以下 folder 位置的路徑。

<ul>
<li><code>tensorflow/tensorflow/contrib/lite/gen/lib</code></li>
</ul></li>
</ul>

<h4 id="target-設定">Target 設定</h4>

<ul>
<li>將 <code>libtensorflow-lite.a</code> 的連結加入 <strong>Build Phases</strong> 設定中的 <strong>Link Binary With Libraries</strong> 裡。</li>
</ul>

<p>設定完成即在可專案中呼叫 TensorFlow Lite API。</p>

<blockquote>
<p>因 TensorFlow Lite 的 API 使用 C++ 寫成，若要在 Objectvie-C 中使用需將呼叫的檔案設定為 <code>*.mm</code> 讓 Xcode 使用 C++ 來編譯。若使用 Swift 來開發則需透過 Objective-C++ wrapper 的方式呼叫，相關方式可參考<a href="https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html">此篇文章</a>。</p>
</blockquote>

<h2 id="使用-tensorflow-lite-api">使用 Tensorflow Lite API</h2>

<p>因 TensorFlow Lite 的 API 使用 C++ 寫成，若要在 Objectvie-C 中使用需將呼叫的檔案設定為 <code>*.mm</code> 以讓 Xcode 可編譯 Objective-C++ 語法。若使用 Swift 來開發則需透過 Objective-C++ wrapper 的方式呼叫，相關方式可參考<a href="https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html">此篇文章</a>。下面程式碼範例部分參考 TensorFlow Lite 的官方 <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/examples/ios">iOS 範例</a>。</p>

<h4 id="匯入-model-檔案到-xcode-專案中">匯入 Model 檔案到 Xcode 專案中</h4>

<p>在使 TensorFlow Lite 前，須先引入 TensorFlow Lite 可使用的 model file ( *.tflite)，在此我們直接使用 Google 所提供的 <a href="http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_0.25_128.tgz">mobilenet_v1_0.25_128</a> Model，將檔案下載並解壓縮後將 <code>mobilenet_v1_0.25_128.tflite</code> 與 <code>labels.txt</code> 複製到專案中。此外也可從自行下載下載<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md">其他模型</a>使用。。</p>

<h4 id="讀取-tensorflow-lite-model">讀取  TensorFlow Lite Model</h4>

<p>使用 NSBundle 中的 <a href="https://developer.apple.com/documentation/foundation/nsbundle/1410989-pathforresource">pathForResource</a>  function 取得 model 檔案路徑後建立 <code>model</code> 物件。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#fb660a;font-weight:bold">auto</span> graph_path = <span style="color:#080;background-color:#0f140f;font-style:italic">/* Get model path */</span>
<span style="color:#fb660a;font-weight:bold">auto</span> model = tflite::FlatBufferModel::BuildFromFile(graph_path.c_str());
</code></pre></div>
<h4 id="建立-interpreter">建立 Interpreter</h4>

<p>建立 Interpreter 物件，並設定所要使用的 model。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#fb660a;font-weight:bold">auto</span> interpreter = std::make_unique&lt;tflite::Interpreter&gt;();
<span style="color:#fb660a;font-weight:bold">auto</span> resolver = tflite::ops::builtin::BuiltinOpResolver();
<span style="color:#fb660a;font-weight:bold">auto</span> builder = tflite::InterpreterBuilder(*model, resolver);
builder(&amp;p_interpreter);
</code></pre></div>
<h4 id="初始化-input-tensor">初始化 Input Tensor</h4>

<p>在執行需先建立 Input tensor，設定維度後分配記憶體空間。因 <strong>mobilenet</strong> 的模型為 <strong>224 * 224 * 3</strong> 的圖片，引此維度需設為 <code>vector&lt;int&gt;{1, 224, 224, 3}</code>。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#080;background-color:#0f140f;font-style:italic">// 設定 Input Tensor 的維度
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>interpreter-&gt;ResizeInputTensor(interpreter-&gt;inputs()[<span style="color:#0086f7;font-weight:bold">0</span>], vector&lt;<span style="color:#cdcaa9;font-weight:bold">int</span>&gt;{<span style="color:#0086f7;font-weight:bold">1</span>, <span style="color:#0086f7;font-weight:bold">224</span>, <span style="color:#0086f7;font-weight:bold">224</span>, <span style="color:#0086f7;font-weight:bold">3</span>);

<span style="color:#080;background-color:#0f140f;font-style:italic">// 建立 Input Tensor 的記憶體空間 (ResizeInputTensor() 後一定要執行)
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>interpreter-&gt;AllocateTensors(); 
</code></pre></div>
<h4 id="設定資料到-input-tensor">設定資料到 Input Tensor</h4>

<p>要設定資料到 Input Tensor，可先取得資料的初始 address 後，計算 Raw Data 中對應的位置後將資料傳入 Input Tensor 中。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#080;background-color:#0f140f;font-style:italic">// 取得輸入的資料初始 Address
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span><span style="color:#cdcaa9;font-weight:bold">float</span>* out = interpreter-&gt;typed_tensor&lt;<span style="color:#cdcaa9;font-weight:bold">float</span>&gt;(interpreter-&gt;inputs()[<span style="color:#0086f7;font-weight:bold">0</span>]);

<span style="color:#080;background-color:#0f140f;font-style:italic">// Raw data 的資料的初始位址
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>uint8_t* in = raw_data.data();  <span style="color:#080;background-color:#0f140f;font-style:italic">// raw_data: 原始資料的 byte array
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>
<span style="color:#080;background-color:#0f140f;font-style:italic">// 設定 model 與 input data 的寬度，高度與 channel 數量
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>size_t model_height = <span style="color:#0086f7;font-weight:bold">224</span>; <span style="color:#080;background-color:#0f140f;font-style:italic">// Model 的輸入高度
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>size_t model_height = <span style="color:#0086f7;font-weight:bold">224</span>;  <span style="color:#080;background-color:#0f140f;font-style:italic">// Model 的輸入寬度
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>size_t model_channels = <span style="color:#0086f7;font-weight:bold">3</span>;  <span style="color:#080;background-color:#0f140f;font-style:italic">// Model 的輸入 Channel 數
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>size_t image_width = <span style="color:#080;background-color:#0f140f;font-style:italic">/* Input data 的高度 */</span>;
size_t image_height = <span style="color:#080;background-color:#0f140f;font-style:italic">/* Input data 的寬度 */</span>;
size_t image_channels = <span style="color:#080;background-color:#0f140f;font-style:italic">/* Input data 的 Channel 數 */</span>;  

<span style="color:#cdcaa9;font-weight:bold">float</span> input_mean = <span style="color:#0086f7;font-weight:bold">127.5f</span>;
<span style="color:#cdcaa9;font-weight:bold">float</span> input_std = <span style="color:#0086f7;font-weight:bold">127.5f</span>;
    
<span style="color:#080;background-color:#0f140f;font-style:italic">// 計算每一個 input data 對應的 input tensor 位置，並將 data 設定至 tensor 中
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span><span style="color:#fb660a;font-weight:bold">for</span> (<span style="color:#cdcaa9;font-weight:bold">int</span> y = <span style="color:#0086f7;font-weight:bold">0</span>; y &lt; model_height; ++y) {
    <span style="color:#cdcaa9;font-weight:bold">int</span> in_y = <span style="color:#fb660a;font-weight:bold">static_cast</span>&lt;<span style="color:#cdcaa9;font-weight:bold">int</span>&gt;(y * image_height / model_height);
    uint8_t* in_row = in + (in_y * image_width * image_channels);
    <span style="color:#cdcaa9;font-weight:bold">float</span>* out_row = out + (y * model_width * model_channels);
    <span style="color:#fb660a;font-weight:bold">for</span> (<span style="color:#cdcaa9;font-weight:bold">int</span> x = <span style="color:#0086f7;font-weight:bold">0</span>; x &lt; model_width; ++x) {
        <span style="color:#fb660a;font-weight:bold">const</span> <span style="color:#cdcaa9;font-weight:bold">int</span> in_x = <span style="color:#fb660a;font-weight:bold">static_cast</span>&lt;<span style="color:#cdcaa9;font-weight:bold">int</span>&gt;(x * image_width / model_width);
        <span style="color:#fb660a;font-weight:bold">const</span> uint8_t* in_pixel = in_row + (in_x * image_channels);
        <span style="color:#cdcaa9;font-weight:bold">float</span>* out_pixel = out_row + (x * model_channels);
        <span style="color:#fb660a;font-weight:bold">for</span> (<span style="color:#cdcaa9;font-weight:bold">int</span> c = <span style="color:#0086f7;font-weight:bold">0</span>; c &lt; model_channels; ++c) {
            <span style="color:#080;background-color:#0f140f;font-style:italic">// 正規化輸入資料
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>            out_pixel[c] = (in_pixel[c] - input_mean) / input_std;
        }
    }
}
</code></pre></div>
<h4 id="執行-tensorflow-lite-model">執行 TensorFlow Lite Model</h4>

<p>當資料設定完成後可呼叫 <code>Interpreter::Invoke()</code> 函式執行 Model。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#080;background-color:#0f140f;font-style:italic">// 使用 Invoke() function 執行設定 model，並確定狀態是否執行成功。
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span>interpreter-&gt;Invoke()
</code></pre></div>
<h4 id="取得執行後的結果">取得執行後的結果</h4>

<p>若執行成功可得出 <strong>MobileNet</strong> 的中對應每個 <strong>Label</strong> 的 score 資訊（Label 的資訊存在 <strong>labels.txt</strong> 中）。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#080;background-color:#0f140f;font-style:italic">// 取得 output tensor 初始位置
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span><span style="color:#cdcaa9;font-weight:bold">float</span>* output = interpreter-&gt;typed_output_tensor&lt;<span style="color:#cdcaa9;font-weight:bold">float</span>&gt;(<span style="color:#0086f7;font-weight:bold">0</span>);

<span style="color:#080;background-color:#0f140f;font-style:italic">// 使用 output 資料建立 Score vector
</span><span style="color:#080;background-color:#0f140f;font-style:italic"></span><span style="color:#fb660a;font-weight:bold">auto</span> scores = vector&lt;<span style="color:#cdcaa9;font-weight:bold">float</span>&gt;(output, output + <span style="color:#0086f7;font-weight:bold">1000</span>); <span style="color:#080;background-color:#0f140f;font-style:italic">// mobilenet 共有 1000 個 labels
</span></code></pre></div>
<h4 id="顯示結果">顯示結果</h4>

<p>在這裡我們用一個簡單的範例來顯示對圖片進行分類的結果。下方 Label 代表使用 MobileNet 分類結果的 Top 5，Label 右方的數值為可能性百分比。</p>

<p><img src="/images/2018/tensorflow-lite-ios/tflite-ios.jpg" alt="tflite-ios" /></p>

<h2 id="reference">Reference</h2>

<ul>
<li><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite">TensorFlow Lite</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/ios.md">TensorFlow Lite for iOS</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/mobile/tflite/devguide.md">Developer Guide</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md">TensorFlow API</a></li>
</ul>
		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/ios/" rel="tag">iOS</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/tensorflow/" rel="tag">TensorFlow</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/classification/" rel="tag">Classification</a></li>
	</ul>
</div>
	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/post/2018/autoencoder-tutorial/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Autoencoder 簡介與應用範例</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/post/2018/modern-cpp-changing/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Modern C&#43;&#43; changing</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "yeshuanova" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2019 Xeno Universe.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/contrib/auto-render.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>renderMathInElement(document.body);</script>
</body>
</html>