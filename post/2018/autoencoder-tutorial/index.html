<!DOCTYPE html>
<html class="no-js" lang="zh-tw">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Autoencoder 簡介與應用範例 - Xeno Universe</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="About Autoencoder theory and examples using MNIST dataset">
	<meta name="generator" content="Hugo 0.54.0" />
	<meta property="og:title" content="Autoencoder 簡介與應用範例" />
<meta property="og:description" content="About Autoencoder theory and examples using MNIST dataset" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/2018/autoencoder-tutorial/" />
<meta property="article:published_time" content="2018-01-04T18:00:00&#43;08:00"/>
<meta property="article:modified_time" content="2018-01-04T18:00:00&#43;08:00"/>

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="shortcut icon" href="/favicon.ico">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-104710641-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="Xeno Universe" rel="home">
				<div class="logo__title">Xeno Universe</div>
				<div class="logo__tagline">A fearless adventure in knowing what to do when no one’s there telling you what to do</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/about/">About</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/competitions/">Competitions</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Autoencoder 簡介與應用範例</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2018-01-04T18:00:00">January 04, 2018</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/categories/machine-learning" rel="category">Machine Learning</a></span>
</div>
</div>
		</header><div class="content post__content clearfix">
			<p>Autoencoder(自動編碼器)是一種是透過 <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">Artificial Neural Network</a>，來進行資料自動學習與編碼的技術。本文將使用機器學習函式庫 <a href="https://keras.io/">Keras</a> 建立 Autoencoder Model，並使用 MNIST Datatset 來展示兩個 Autoencoder 範例 - <strong>資料降維回復</strong>與<strong>去雜訊(Denoising)</strong>的 Model。</p>

<h1 id="autoencoder">Autoencoder</h1>

<p>什麼是 Autoencoder ? 簡單來說是一種透過<strong>類神經網路</strong>來自動學習資料中的<strong>特徵</strong>，以達成特定功能如 Dimension Reduction，Data Denoising 等功能的模型。</p>

<p>該模型主要包含三部分 - <strong>Encoding Function</strong> <span  class="math">\(h = f(x)\)</span>， <strong>Decoding Function</strong> <span  class="math">\(r = g(h)\)</span> 與 <strong>Loss function</strong> <span  class="math">\(L(x, r)\)</span>。我們希望輸入壓縮後的資料在復原後能盡可能接近原始資料，即 <span  class="math">\(x \approx r\)</span>。下圖為 Autoencoder 基本架構</p>

<p><figure><img src="/images/2018/autoencoder/autoencoder_structure.png" alt="framework"></figure>
<em>Autoencoder Structure (From: Wikipedia)</em></p>

<p>與一般的資料壓縮演算法如 Zip, MP3，JPG 等通用演算法不同，Autoencoder 有資料相依的性質。即訓練完成的 Model 只適用於特定類型資料且會損失(lossy)原始資訊。但由於 Autoencoder 不需要標示 Label 以及能自動學習的特性，可以幫助解決 Unsupervised Learning 的問題，因此仍然存在著許多發展潛力。</p>

<h2 id="regularized-autoencoders">Regularized Autoencoders</h2>

<p>在 Autoencoder 中，Code 的維度比輸入資料<strong>小</strong>的模型稱為 <strong>Undercomplete Autoencoder</strong>，比輸入資料<strong>大</strong>的則稱為 <strong>Overcomplete Autoencoder</strong>。上例即為 <strong>Undercomplete Autoencoder</strong> 的範例。</p>

<p>由於 Autoencoder 主要目的為希望能學習到資料特徵，若只是單純回復輸入得資料通常意義不大，因此比起限制 Code 維度大小，通常更傾向使 Autoencoder Model 去學習某些的特性，讓 Model 能達到特定效果。這些 Model 也被稱為 Regularized Autoencoder，如下例的 <strong>DAE(Denoising Autoencoder)</strong> 即是 Code 維度比輸入資料更大的 Model。</p>

<h2 id="examples">Examples</h2>

<p>以下將使用 <a href="https://keras.io/">Keras</a> 函式庫並使用 <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> Dataset 來展示兩個 Autoencoder 範例，基本 Autoencoder 架構與 Denoising Autoencoder。該範例主要來自 <a href="https://blog.keras.io/building-autoencoders-in-keras.html">Building Autoencoders in Keras</a> 這篇文章，若需要更深入的理解可自行參考相關內容。</p>

<h3 id="mnist-資料降維與復原">MNIST 資料降維與復原</h3>

<p>MNIST 為一著名的手寫辨識資料集，在此範例中使用 Fully-Connection Neural Network，將 <strong>28 * 28 = 784</strong> 維的圖片轉換成 <strong>32</strong> 維的 Encoding Layer 後，再還原至原先的 <strong>28 * 28</strong> 維影像資料並比較雙方差異。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;background-color:#0f140f;font-style:italic"># 讀取 MNIST dataset 並進行前處理</span>
<span style="color:#fb660a;font-weight:bold">from</span> keras.datasets <span style="color:#fb660a;font-weight:bold">import</span> mnist
<span style="color:#fb660a;font-weight:bold">import</span> numpy <span style="color:#fb660a;font-weight:bold">as</span> np

<span style="color:#080;background-color:#0f140f;font-style:italic"># x_train: Autoencoder 訓練資料</span>
<span style="color:#080;background-color:#0f140f;font-style:italic"># x_test: Autoencoder 測試資料</span>
(x_train, _), (x_test, _) = mnist.load_data()

x_train = x_train.astype(<span style="color:#0086d2">&#39;float32&#39;</span>) / <span style="color:#0086f7;font-weight:bold">255.</span> <span style="color:#080;background-color:#0f140f;font-style:italic"># 正規化資料數值範圍至 [0, 1] 間</span>
x_test = x_test.astype(<span style="color:#0086d2">&#39;float32&#39;</span>) / <span style="color:#0086f7;font-weight:bold">255.</span>

<span style="color:#080;background-color:#0f140f;font-style:italic"># 正規化資料維度，以便 Keras 處理</span>
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[<span style="color:#0086f7;font-weight:bold">1</span>:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[<span style="color:#0086f7;font-weight:bold">1</span>:])))</code></pre></div>
<p>資料讀取完成後，接著建立 Autoencoder Model 並使用 <code>x_train</code> 資料進行訓練。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#fb660a;font-weight:bold">from</span> keras.layers <span style="color:#fb660a;font-weight:bold">import</span> Input, Dense
<span style="color:#fb660a;font-weight:bold">from</span> keras.models <span style="color:#fb660a;font-weight:bold">import</span> Model

input_img = Input(shape=(<span style="color:#0086f7;font-weight:bold">784</span>,))
encoded = Dense(<span style="color:#0086f7;font-weight:bold">32</span>, activation=<span style="color:#0086d2">&#39;relu&#39;</span>)(input_img) <span style="color:#080;background-color:#0f140f;font-style:italic">## Encoding layer 設為 32 維</span>
decoded = Dense(<span style="color:#0086f7;font-weight:bold">784</span>, activation=<span style="color:#0086d2">&#39;sigmoid&#39;</span>)(encoded) <span style="color:#080;background-color:#0f140f;font-style:italic">## Decoding layer 設為與 input layer 相同的 784 維</span>

<span style="color:#080;background-color:#0f140f;font-style:italic"># 建立 Model 並將 loss funciton 設為 binary cross entropy</span>
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer=<span style="color:#0086d2">&#39;adadelta&#39;</span>, loss=<span style="color:#0086d2">&#39;binary_crossentropy&#39;</span>)

autoencoder.fit(x_train,
                x_train,  <span style="color:#080;background-color:#0f140f;font-style:italic"># Label 也設為 x_train</span>
                epochs=<span style="color:#0086f7;font-weight:bold">25</span>,
                batch_size=<span style="color:#0086f7;font-weight:bold">128</span>,
                shuffle=True,
                validation_data=(x_test, x_test))</code></pre></div>
<p>訓練完後可以得到 <strong>loss</strong> 值約為 <code>0.1049</code> 以及 <strong>Validation loss</strong> 為 <code>0.1029</code> 的 Autoencoder Model。下圖為將 <code>x_test</code> 資料輸入 <code>autoencoder</code> 物件後的得到的結果圖片。</p>

<p><figure><img src="/images/2018/autoencoder/nn_autoencoder_comparison.png" alt="nn_imaga_comparision"></figure>
<em>(Top) 原始影像。 (Middle) 32維編碼資料以 $8 \times 4$ 平面呈現。 (Bottom) 輸出結果。</em></p>

<p>從上圖可看出，即使將原先 28*28 = 784 維的資料轉換到 32 維的資料後再復原回原先的圖片，仍能保留相關特徵存在。</p>

<h3 id="denosing-autoencoder-dae">Denosing Autoencoder (DAE)</h3>

<p>最初的 Autoencoder 為使用相同的輸入與輸出來建立 Model，但我們也可以對 Model 做一些修改來達成其他效果。如對輸入的資料 <span  class="math">\(x\)</span> 加入的 noise 使 <span  class="math">\(\tilde{x}=noise(x)\)</span>。現在使用 <span  class="math">\(\tilde{x}\)</span> 做為訓練資料而 <span  class="math">\(x\)</span> 為輸出結果進行訓練。即讓 Loss function 為 <span  class="math">\(L(x, g( f( \tilde{x} )))\)</span> 可得到一個對原始資料具有去雜訊功能的 Model。</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">noise_factor = <span style="color:#0086f7;font-weight:bold">0.5</span> <span style="color:#080;background-color:#0f140f;font-style:italic"># 決定 noise 的數量，值越大 noise 越多</span>
x_train_noisy = x_train + noise_factor * np.random.normal(loc=<span style="color:#0086f7;font-weight:bold">0.0</span>, scale=<span style="color:#0086f7;font-weight:bold">1.0</span>, size=x_train.shape)
x_test_noisy = x_test + noise_factor * np.random.normal(loc=<span style="color:#0086f7;font-weight:bold">0.0</span>, scale=<span style="color:#0086f7;font-weight:bold">1.0</span>, size=x_test.shape)

<span style="color:#080;background-color:#0f140f;font-style:italic"># 將資料限制在 [0, 1] 之間的範圍內</span>
x_train_noisy = np.clip(x_train_noisy, <span style="color:#0086f7;font-weight:bold">0.</span>, <span style="color:#0086f7;font-weight:bold">1.</span>)
x_test_noisy = np.clip(x_test_noisy, <span style="color:#0086f7;font-weight:bold">0.</span>, <span style="color:#0086f7;font-weight:bold">1.</span>)</code></pre></div>
<p>使用加入 Noise 的資料建立 Autoencoder Model 並進行訓練</p>
<div class="highlight"><pre style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">input_img = Input(shape=(<span style="color:#0086f7;font-weight:bold">28</span>, <span style="color:#0086f7;font-weight:bold">28</span>, <span style="color:#0086f7;font-weight:bold">1</span>))
x = Conv2D(<span style="color:#0086f7;font-weight:bold">32</span>, (<span style="color:#0086f7;font-weight:bold">3</span>, <span style="color:#0086f7;font-weight:bold">3</span>), activation=<span style="color:#0086d2">&#39;relu&#39;</span>, padding=<span style="color:#0086d2">&#39;same&#39;</span>)(input_img)
x = MaxPooling2D((<span style="color:#0086f7;font-weight:bold">2</span>, <span style="color:#0086f7;font-weight:bold">2</span>), padding=<span style="color:#0086d2">&#39;same&#39;</span>)(x)
x = Conv2D(<span style="color:#0086f7;font-weight:bold">32</span>, (<span style="color:#0086f7;font-weight:bold">3</span>, <span style="color:#0086f7;font-weight:bold">3</span>), activation=<span style="color:#0086d2">&#39;relu&#39;</span>, padding=<span style="color:#0086d2">&#39;same&#39;</span>)(x)

<span style="color:#080;background-color:#0f140f;font-style:italic"># encoded size = (7, 7, 32) dimension</span>
encoded = MaxPooling2D((<span style="color:#0086f7;font-weight:bold">2</span>, <span style="color:#0086f7;font-weight:bold">2</span>), padding=<span style="color:#0086d2">&#39;same&#39;</span>)(x) 

x = Conv2D(<span style="color:#0086f7;font-weight:bold">32</span>, (<span style="color:#0086f7;font-weight:bold">3</span>, <span style="color:#0086f7;font-weight:bold">3</span>), activation=<span style="color:#0086d2">&#39;relu&#39;</span>, padding=<span style="color:#0086d2">&#39;same&#39;</span>)(encoded)
x = UpSampling2D((<span style="color:#0086f7;font-weight:bold">2</span>, <span style="color:#0086f7;font-weight:bold">2</span>))(x)
x = Conv2D(<span style="color:#0086f7;font-weight:bold">32</span>, (<span style="color:#0086f7;font-weight:bold">3</span>, <span style="color:#0086f7;font-weight:bold">3</span>), activation=<span style="color:#0086d2">&#39;relu&#39;</span>, padding=<span style="color:#0086d2">&#39;same&#39;</span>)(x)
x = UpSampling2D((<span style="color:#0086f7;font-weight:bold">2</span>, <span style="color:#0086f7;font-weight:bold">2</span>))(x)

<span style="color:#080;background-color:#0f140f;font-style:italic"># Decoded size = (28, 28, 1) dimension (Original size)</span>
decoded = Conv2D(<span style="color:#0086f7;font-weight:bold">1</span>, (<span style="color:#0086f7;font-weight:bold">3</span>, <span style="color:#0086f7;font-weight:bold">3</span>), activation=<span style="color:#0086d2">&#39;sigmoid&#39;</span>, padding=<span style="color:#0086d2">&#39;same&#39;</span>)(x)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer=<span style="color:#0086d2">&#39;adadelta&#39;</span>, loss=<span style="color:#0086d2">&#39;binary_crossentropy&#39;</span>)

<span style="color:#080;background-color:#0f140f;font-style:italic"># 訓練 DAE Model</span>
autoencoder.fit(x_train_noisy, <span style="color:#080;background-color:#0f140f;font-style:italic"># 加入 noise 的資料為輸入</span>
                x_train,  <span style="color:#080;background-color:#0f140f;font-style:italic"># 原始資料為 Label</span>
                epochs=<span style="color:#0086f7;font-weight:bold">20</span>,
                batch_size=<span style="color:#0086f7;font-weight:bold">256</span>,
                shuffle=True,
                validation_data=(x_test_noisy, x_test))</code></pre></div>
<p>訓練後可得到一個 Denoising Autoencoder Model。現建立加入不同雜訊數量的 MNIST 影像資料輸入訓練完成的 DAE 中得到的 denoising 的結果。</p>

<p><figure><img src="/images/2018/autoencoder/denoising_origin.png" alt="DAE_Origin"></figure>
<em>Original Image</em></p>

<p><figure><img src="/images/2018/autoencoder/denoising_factor_0.2.png" alt="DAE_factor_0.2"></figure>
<em>Noise = 0.2</em></p>

<p><figure><img src="/images/2018/autoencoder/denoising_factor_0.5.png" alt="DAE_factor_0.5"></figure>
<em>Noise = 0.5</em></p>

<p><figure><img src="/images/2018/autoencoder/denoising_factor_0.8.png" alt="DAE_factor_0.8"></figure>
<em>Noise = 0.8</em></p>

<p>可以看出訓練之後的模型，對不同程度的雜訊都有一定的抗噪作用，能回覆原先大部分的結構。即使是使用 Noise = 0.5 的資料加以訓練，也能一定程度回覆 Noise = 0.8 的資料內容。</p>

<h2 id="reference">Reference</h2>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Autoencoder">Autoencoder on Wikipedia</a></li>
<li><a href="http://www.deeplearningbook.org/">Deep Learning Book</a></li>
<li><a href="https://keras.io/">Keras Office Website</a></li>
<li><a href="https://blog.keras.io/building-autoencoders-in-keras.html">Building Autoencoders in Keras</a></li>
<li><a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a></li>
</ul>
		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/neural-network/" rel="tag">Neural Network</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/autoencoder/" rel="tag">Autoencoder</a></li>
	</ul>
</div>
	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/post/2017/python-visualization-datashader/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Python 資料視覺化 - 使用 datashader</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/post/2018/tensorflow-lite-in-ios-device/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">使用 TensorFlow Lite 在 iOS 裝置上進行圖片分類</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "yeshuanova" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2019 Xeno Universe.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/contrib/auto-render.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>renderMathInElement(document.body);</script>
</body>
</html>