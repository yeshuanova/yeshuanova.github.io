<!DOCTYPE html>
<html class="no-js" lang="zh-tw">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>從圍棋到星海爭霸 - 淺談人工智慧的挑戰 (1) - Xeno Universe</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="AI challenge from board game to StarCraft 2">
	<meta name="generator" content="Hugo 0.54.0" />
	<meta property="og:title" content="從圍棋到星海爭霸 - 淺談人工智慧的挑戰 (1)" />
<meta property="og:description" content="AI challenge from board game to StarCraft 2" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/2017/from-go-to-sc2-part-1/" />
<meta property="article:published_time" content="2017-09-05T14:00:00&#43;08:00"/>
<meta property="article:modified_time" content="2017-09-05T14:00:00&#43;08:00"/>

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="shortcut icon" href="/favicon.ico">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-104710641-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="Xeno Universe" rel="home">
				<div class="logo__title">Xeno Universe</div>
				<div class="logo__tagline">A fearless adventure in knowing what to do when no one’s there telling you what to do</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/about/">About</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/competitions/">Competitions</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">從圍棋到星海爭霸 - 淺談人工智慧的挑戰 (1)</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2017-09-05T14:00:00">September 05, 2017</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/categories/machine-learning" rel="category">Machine Learning</a>, <a class="meta__link" href="/categories/deep-learning" rel="category">Deep Learning</a></span>
</div>
</div>
		</header><div class="content post__content clearfix">
			<p>從AI黎明期開始，如<a href="https://en.wikipedia.org/wiki/Chess">西洋棋(chess)</a>，<a href="https://en.wikipedia.org/wiki/Go_(game)">圍棋(Go)</a>或<a href="https://en.wikipedia.org/wiki/Xiangqi">象棋</a>等棋類遊戲一直是人工智慧的研究與測試領域。但由於早期的計算機的能力限制以及演算法的發展，較為複雜的棋類遊戲仍無法打敗世界級水準的棋手。直到1997年時IBM的<a href="https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)">深藍(Deep Blue)</a>在西洋棋比賽中打敗了世界棋王<a href="https://en.wikipedia.org/wiki/Garry_Kasparov">Garry Kasparov</a>，展現了電腦也能夠在西洋棋上打敗人類世界頂尖棋手的實力。</p>

<p><figure><img src="/images/2017/ai-challenge/Kasparov-DeepBlue.png" alt="Kasparov-DeepBlue"></figure>
<em>Garry Kasparov與Deep Blue的西洋棋競賽(From: Stanford CS221 Page)</em></p>

<p>雖然西洋棋已被Deep Blue攻克，但圍棋領域仍然屹立不搖。和西洋棋相比，圍棋的複雜度高上太多，如果以19x19的圍棋盤面大小來說狀態變化就有約<span  class="math">\(10^{172}\)</span>種可能性。這是一個非常龐大的數量，即使是使用現代的Super Computer也在有限時間內列舉所有可能性。也因此圍棋一直被認為是電腦無法短時間內到達人類的頂尖水準。</p>

<h2 id="alphago--深度學習技術展示">AlphaGo - 深度學習技術展示</h2>

<p>當各大公司如Facebook都推出自己的圍棋程式<a href="https://en.wikipedia.org/wiki/Darkforest">Darkforest</a>時，一家被Google收購的英國AI公司<a href="https://deepmind.com/">DeepMind</a>，卻以自家開發的<a href="https://deepmind.com/research/alphago/">AlphaGo</a>直接對圍棋界頂尖的韓國棋手<a href="https://en.wikipedia.org/wiki/Lee_Sedol">李世乭(Lee Sedol)</a>發出了對弈挑戰，最後敲定2016年3月在韓國舉行比賽。</p>

<p><figure><img src="/images/2017/ai-challenge/alphago_vs_lee.jpg" alt="AlphaGo_vs_Lee"></figure>
<em>AlphaGo與李世乭在首爾的人機大戰(From: Go Game Guru)</em></p>

<p>一開始許多<a href="http://sports.sina.com.cn/go/2016-03-01/doc-ifxpvysv5028824.shtml">圍棋界人士</a>認為，AlphaGo為要在圍棋領域<a href="https://www.inside.com.tw/2016/02/24/google-alphago-lee-se-dol">擊敗人類世界頂尖棋手</a>，現階段來說非常困難。但許多資訊領域的人士則認為AlphaGo有很大的勝率<a href="https://www.hksilicon.com/articles/1030548">擊敗李世乭</a>。但最後結果卻大出賽前的圍棋專家預料，AlphaGo以4：1擊敗李世乭。且在對弈的過程中AlphaGo展現出來許多令人無法理解，但卻能有效地達到獲勝的目的棋步。</p>

<h2 id="master--網路上的圍棋幽靈sai">Master - 網路上的圍棋幽靈Sai</h2>

<p>在與AlphaGo對弈後一年，2017年1月<a href="http://www.foxwq.com/">中國圍棋網</a>忽然出現了一位神秘棋手<a href="https://en.wikipedia.org/wiki/Master_(software)">Master</a>，在快棋規則下交出了驚人的60戰全勝，其中還包含了古力，井山裕太等知名圍棋棋士。也因為與圍棋漫畫棋魂中，藤原佐為藉由主角近藤光下網路圍棋打敗重大高手的情節相仿，因此Master也在網路上被戲稱是Sai再現(Sai是漫畫中藤原佐為使用的網路名稱)。在60勝後DeepMind也公布了Master就是升級版的AlphaGo，之後更在2017年5月的<a href="https://en.wikipedia.org/wiki/Future_of_Go_Summit">中國烏鎮圍棋峰會</a>以3:0擊敗了當時世界排名第一的<a href="https://en.wikipedia.org/wiki/Ke_Jie">柯潔</a>。</p>

<p><figure><img src="/images/2017/ai-challenge/alphago_vs_kejie.jpg" alt="AlphaGo_vs_KeJie"></figure>
<em>AlphaGo(Master)與柯潔的比賽</em></p>

<p>而比賽結束後DeepMind也宣布AlphaGo將<a href="https://www.engadget.com/2017/05/27/googles-alphago-retires-from-competition/">引退</a>不再參加圍棋比賽，並在網路上開放Master版AlphaGo的<a href="https://deepmind.com/research/alphago/alphago-vs-alphago-self-play-games/">自我對弈棋譜</a>，十足意味著AI已在圍棋領域<strong>封頂</strong>了。</p>

<h2 id="alphago的挑戰--最佳落子位置">AlphaGo的挑戰 - 最佳落子位置</h2>

<h3 id="強化學習reinforcement-learning">強化學習(Reinforcement Learning)</h3>

<p>有別專注在單一輸出結果的<a href="https://en.wikipedia.org/wiki/Supervised_learning">監督式學習</a>(Supervised learning)與<a href="https://en.wikipedia.org/wiki/Unsupervised_learning">非監督式學習</a>(Unsupervised learning)，棋類遊戲中則是使用到<a href="https://en.wikipedia.org/wiki/Reinforcement_learning">強化學習</a>(Reinforcement Learning)的概念。監督式學習的模型從輸入資料中得出得出一個結果，我們可以用那個結果檢證是否正確。但在強化學習中，單一輸出並不像監督式學習中那麼重要，真正重要的是<strong>&quot;一連串輸出後所得到的結果&quot;</strong>。因此強化學習注重的是，所有動作(Action)執行完後的結果是否符合預期，而棋類遊戲正好符合這樣的概念 - <strong>&quot;觀察盤面狀態，決定下一手直到結束&quot;</strong>。</p>

<p><figure><img src="/images/2017/ai-challenge/RF_diagram.png" alt="rf_diagram"></figure>
<em>強化學習概念圖(From: Wikipedia)</em></p>

<p>從途中可看出，觀察者觀察整個<strong>環境(Environment)</strong>後，將現在的<strong>狀態(State)</strong>與<strong>回饋值(Reward)</strong>傳給<strong>代理人(Agent)</strong>依照<strong>策略(Policy)</strong>決定下一步驟動作，不斷重複直到結束為止。</p>

<h3 id="alphago的架構">AlphaGo的架構</h3>

<p>雖然Agent要決定的動作很單純，但圍棋的狀態複雜度非常高，要暴力解幾乎不可能。因此AlphaGo採用了兩個<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">深度卷積神經網絡</a>(CNN) - <strong>&quot;策略網路(Policy Network)&quot;</strong>與<strong>&quot;值網路(Value Network)&quot;</strong>。並配合<a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search">蒙地卡羅樹狀搜尋</a>(MCTS, Monte Carlo Tree Search)演算法，依照當前盤面進行評估最佳落子位置。</p>

<ul>
<li><p>策略網路(Policy Network)：輸入現在盤面狀態，預測下一步最可能下子位置。</p></li>

<li><p>值網路(Value Network)：輸入現在盤面狀態，得出目前盤面勝率，可用來減少搜尋深度。</p></li>
</ul>

<p><figure><img src="/images/2017/ai-challenge/alphago_network.jpg" alt="Alpha_Go_Network"></figure>
<em>策略網路(Policy Network)與值網路(Value Network))</em></p>

<h3 id="訓練步驟">訓練步驟</h3>

<ul>
<li><p>由<a href="https://www.gokgs.com/">KGS(KGS Go Server)</a>上的過去三百萬場以上的對弈資料，訓練策略網路<span  class="math">\(P_\sigma\)</span>與快速下子策略網路<span  class="math">\(P_\pi\)</span>。</p></li>

<li><p>以<span  class="math">\(P_\sigma\)</span>為基礎，依勝率訓練強化學習策略網路<span  class="math">\(P_\rho\)</span>。</p></li>

<li><p>由強化學習策略網路不斷的自我對弈，來學習價值網路<span  class="math">\(\nu_{\theta}\)</span></p></li>
</ul>

<p><figure><img src="/images/2017/ai-challenge/alphago_training_piple.jpg" alt="Alpha_Go_Pipeline"></figure>
<em>AlphaGo 訓練流程</em></p>

<h3 id="落子決策">落子決策</h3>

<p>AlphaGo在落子時，主要是依靠蒙地卡羅樹狀搜尋(MCTS)演算法提供決策框架。所謂的MCTS是一種啟發式搜尋演算法，時常用在遊戲內的決策系統。可分為四個主要步驟</p>

<ul>
<li><p><strong>Selection</strong>：從根節點<strong>R</strong>依照選擇策略，開始選擇連續的子節點，直到葉節點<strong>L</strong>為止。</p></li>

<li><p><strong>Expansion</strong>：若是葉節點還不能判斷是否結束，則由該節點繼續往下建立新節點。</p></li>

<li><p><strong>Simulation</strong>：從新節點進行模擬以決定該點的結果為何。(Ex.如0代表輸，1代表贏)</p></li>

<li><p><strong>Back-propagation</strong>：將Simulation步驟得出的結果傳遞回跟節點<strong>R</strong></p></li>
</ul>

<p>AlphaGo則將訓練好的策略網路<span  class="math">\(P_\sigma\)</span>，<span  class="math">\(P_\pi\)</span>與值網路<span  class="math">\(\nu_{\theta}\)</span>應用到MCTS中的<strong>Expansion</strong>與<strong>Simulation</strong>步驟，作為落子預測以及結果估計用函數，用以搜尋最佳落子位置。如下圖所示</p>

<p><figure><img src="/images/2017/ai-challenge/alphago_mcts.jpg" alt="Alpha_Go_Pipeline"></figure>
<em>AlphaGo的蒙地卡羅樹狀搜尋架構</em></p>

<p>之後的<strong>Master</strong>版本仍延續了這個基礎架構，但不同的是DeepMind改善了演算法，效能前一版高出10倍，且並用新一代的<a href="https://en.wikipedia.org/wiki/Tensor_processing_unit">TPU</a>來進行運算(與李世乭對弈時用了50台併聯TPU，而與柯潔對弈只用了單機版TPU)。而最重要的改變，就是使用<a href="https://www.wired.com/2017/05/googles-alphago-levels-board-games-power-grids/">AlphaGo自我對弈</a>的棋譜來進行策略網路的訓練，而不依賴人類初始結果，讓AlphaGo在不斷自我對弈中修正策略網路與值網路，進而達到更好的效果。</p>

<h2 id="alphago其實不聰明">AlphaGo其實不聰明?</h2>

<p>雖然AlphaGo雖然展現了超越人類頂尖圍棋手的能力，但是還是屬於弱人工智慧(Narrow AI)的範疇 - 即只能處理<strong>特定領域</strong>問題，並沒有考慮到更多面向的範疇。因此雖然能打敗世界圍棋高手，卻無法像<a href="https://www.ibm.com/watson/">IBM Watson</a>一樣，去處理自然語言和人類語意，並在<a href="https://en.wikipedia.org/wiki/Jeopardy!">Jeopardy</a>上打敗人類常勝冠軍，因兩者的演算法與系統截然不同。</p>


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/WFR3lOm_xhE" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


<p>此外西洋棋或圍棋在性質上是一個<strong>完全資訊(Perfect information)</strong>系統，所有所有雙方狀態與變化都是可以被觀測，不存在隱藏的狀態，此外也不存在系統中常有的雜訊狀態。不像撲克牌遊戲如<a href="https://en.wikipedia.org/wiki/Texas_hold_%27em">德州撲克</a>，存在著不確定對方手牌的狀況。因此對圍棋的挑戰，都是如何找出最適當的演算法，去減少計算複雜度與增加勝率。</p>

<p>此外一個人工智慧系統的行為，也與他的估值函數息息相關，AlphaGo採用了輸/贏來當作目標值，那演算法自然會尋找最穩的方式落子，因此在對弈中有人懷疑明明下另外一子可以贏更多目，但為何不做就是這個緣故。</p>

<p>在下一篇我們將會介紹DeepMind對<a href="http://tw.battle.net/sc2/zh/">星海爭霸2</a>遊戲的挑戰，即DeepMind如何處理不完全資訊(Imperfect information)與以及多重代理人系統時，所遇到的問題與挑戰。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
<li><p><a href="https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf">AlphaGo Pager</a></p></li>

<li><p><a href="https://en.wikipedia.org/wiki/Master_(software)">AlphaGo(Master)</a></p></li>

<li><p><a href="https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/">Google DeepMind's AlphaGo: How it works</a></p></li>

<li><p><a href="https://medium.com/@Synced/alphago-the-ultimate-go-master-7008ac4ce488">AlphaGo: The Ultimate Go Master</a></p></li>

<li><p><a href="http://www.sohu.com/a/143092581_473283">AlphaGo Master最新架构和算法，谷歌云与TPU拆解</a></p></li>
</ul>
		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/deepmind/" rel="tag">DeepMind</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/go/" rel="tag">Go</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/starcraft/" rel="tag">StarCraft</a></li>
	</ul>
</div>
	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/post/2017/isomap/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Isomap - Isometric Mapping</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/post/2017/python-visulization-folium/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Python 地圖視覺化 - 使用 Folium</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "yeshuanova" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2019 Xeno Universe.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/contrib/auto-render.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>renderMathInElement(document.body);</script>
</body>
</html>